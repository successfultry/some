{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary Libraries"
      ],
      "metadata": {
        "id": "6fSARsaSOCs0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2nZLEAILnjb",
        "outputId": "4599013b-4915-4ca0-85b5-0da9838f8fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.9/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aiogram in /usr/local/lib/python3.9/dist-packages (2.25.1)\n",
            "Requirement already satisfied: magic-filter>=1.0.9 in /usr/local/lib/python3.9/dist-packages (from aiogram) (1.0.9)\n",
            "Requirement already satisfied: Babel<2.10.0,>=2.9.1 in /usr/local/lib/python3.9/dist-packages (from aiogram) (2.9.1)\n",
            "Requirement already satisfied: aiohttp<3.9.0,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from aiogram) (3.8.4)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.9/dist-packages (from aiogram) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<3.9.0,>=3.8.0->aiogram) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<3.9.0,>=3.8.0->aiogram) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<3.9.0,>=3.8.0->aiogram) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<3.9.0,>=3.8.0->aiogram) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<3.9.0,>=3.8.0->aiogram) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp<3.9.0,>=3.8.0->aiogram) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<3.9.0,>=3.8.0->aiogram) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.9/dist-packages (from Babel<2.10.0,>=2.9.1->aiogram) (2022.7.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.9/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.9.0,>=3.8.0->aiogram) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.9/dist-packages (0.25.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: NRCLex in /usr/local/lib/python3.9/dist-packages (3.0.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (from NRCLex) (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.9/dist-packages (from textblob->NRCLex) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob->NRCLex) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob->NRCLex) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob->NRCLex) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob->NRCLex) (2022.10.31)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.9/dist-packages (0.2.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.9/dist-packages (1.5.6)\n"
          ]
        }
      ],
      "source": [
        "import os  #To work with files\n",
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "!pip install aiogram #To make Telegram bot work faster\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.utils import executor\n",
        "import soundfile\n",
        "!pip install pydub  # Manipulate audio with an simple and easy high level interface\n",
        "from pydub import AudioSegment\n",
        "from textblob import TextBlob\n",
        "!pip install NRCLex\n",
        "import string\n",
        "from nrclex import NRCLex\n",
        "import plotly.express as px\n",
        "#import plotly.io as pio\n",
        "import nltk\n",
        "import pandas as pd\n",
        "!pip install -U kaleido\n",
        "nltk.download('punkt')\n",
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bot's inicialization"
      ],
      "metadata": {
        "id": "4u-hhDSqPRqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BOT_TOKEN = \"5886152347:AAFi7GkV-4Xh5GhirsZSFHod5IZ01flbCPU\"\n",
        "bot = Bot(token=BOT_TOKEN)\n",
        "dp = Dispatcher(bot)"
      ],
      "metadata": {
        "id": "JrkmnViLN_1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function for converting audio to text and for analyzing lyrics' polarity and emotions\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "26_Qgs4tPdpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_audio(audio_file):\n",
        "    # Process the downloaded audio file otherwise we have an error below:\n",
        "    # \"ValueError: Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format mp3\"\n",
        "    data, samplerate = soundfile.read(audio_file)\n",
        "    soundfile.write('music/new.wav', data, samplerate, subtype='PCM_16')\n",
        "\n",
        "    #Returns an AudioSegment object from the given file based on its file extension.\n",
        "    audio_file = AudioSegment.from_file(\"music/new.wav\", format=\"wav\")\n",
        "    file_length = len(audio_file)\n",
        "    segment_length = 10 * 1000  # 10 seconds in milliseconds\n",
        "\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "    text = \"\"\n",
        "\n",
        "    #we divide the audio file into segments of 10 seconds (this is necessary because speech_recognition cannot work with long files)\n",
        "    for i in range(0, file_length, segment_length):\n",
        "        audio_segment = audio_file[i:i + segment_length]\n",
        "        audio_segment.export(f\"music/audio_segment_{i // segment_length + 1}.wav\", format=\"wav\")\n",
        "\n",
        "    # we get the text from each segment\n",
        "    for i in range(0, file_length, segment_length):\n",
        "        print(f\"Processing of {i // segment_length + 1} segment\")\n",
        "\n",
        "        try:\n",
        "            #Do 'with' in order not to do open/close file\n",
        "            with sr.AudioFile(f\"music/audio_segment_{i // segment_length + 1}.wav\") as source:\n",
        "                audio = r.record(source)\n",
        "\n",
        "            text_segment = \"\"\n",
        "\n",
        "            segment = r.recognize_google(audio, language='en-US', show_all=True)\n",
        "\n",
        "            #To check if segment has a list type\n",
        "            if isinstance(segment, list):\n",
        "                continue\n",
        "\n",
        "            #\n",
        "            if segment.get('alternative') is not None:\n",
        "                for part_text_segment in r.recognize_google(audio, language='en-US', show_all=True).get('alternative'):\n",
        "                    transcript = part_text_segment.get('transcript')\n",
        "                    if transcript is not None:\n",
        "                        text_segment += transcript\n",
        "\n",
        "            text += text_segment\n",
        "\n",
        "        except Exception:\n",
        "            ...\n",
        "\n",
        "    folder_path = './music'\n",
        "\n",
        "    #Remove previous files in order to free space\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                os.rmdir(file_path)\n",
        "        except Exception as e:\n",
        "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
        "\n",
        "    #NRCLex emotions analysis\n",
        "    text_object = NRCLex(text)\n",
        "    #data = text_object.raw_emotion_scores\n",
        "    data = text_object.affect_frequencies\n",
        "    print(data)\n",
        "    # print()\n",
        "\n",
        "    emotion_df = pd.DataFrame.from_dict(data, orient='index')\n",
        "    emotion_df = emotion_df.reset_index()\n",
        "    emotion_df = emotion_df.rename(columns={'index': 'Emotion Classification', 0: 'Emotion Frequency'})\n",
        "    emotion_df = emotion_df.sort_values(by=['Emotion Frequency'], ascending=False)\n",
        "    print(emotion_df)\n",
        "\n",
        "    fig = px.bar(emotion_df, x='Emotion Frequency', y='Emotion Classification', color='Emotion Frequency',\n",
        "                 orientation='h', width=800, height=400)\n",
        "    fig.show()\n",
        "    #pio.write_image(fig, \"op.png\")\n",
        "    fig.write_image(\"emotions.jpg\")\n",
        "\n",
        "\n",
        "    #We make an assessment of the text from the audio according to the mood\n",
        "    analysis = TextBlob(text.strip()).sentiment\n",
        "    print(analysis.polarity)\n",
        "\n",
        "    if analysis.polarity >= -0.05 and analysis.polarity <= 0.05:\n",
        "        return \"The audio is generally neutral in mood\"\n",
        "    elif analysis.polarity > 0.05 and analysis.polarity <= 0.5:\n",
        "        return \"The audio is generally positive\"\n",
        "    elif analysis.polarity >= -0.5 and analysis.polarity < 0.05:\n",
        "        return \"The audio is generally negative\"\n",
        "    elif analysis.polarity > 0.5:\n",
        "        return \"The audio is much positive\"\n",
        "    elif analysis.polarity < -0.5:\n",
        "        return \"The audio is much negative\""
      ],
      "metadata": {
        "id": "KvNrU5k-N_8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bot's handlers"
      ],
      "metadata": {
        "id": "LqHJ3EaFWRDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  /start command Handler\n",
        "@dp.message_handler(commands=['start'])\n",
        "async def send_welcome(message: types.Message):\n",
        "    await message.reply(\"¡Hola! Soy un bot para convertir audio a texto.\")\n",
        "\n",
        "#  /help command Handler\n",
        "@dp.message_handler(commands=['help'])\n",
        "async def send_welcome(message: types.Message):\n",
        "    \"\"\"\n",
        "    This handler will be called when user sends `/help` command\n",
        "    \"\"\"\n",
        "    await message.reply(\"Envíame un archivo de audio y te devolveré el sentimiento y las emociones que de la letra de la cancion.\")"
      ],
      "metadata": {
        "id": "Ub5NlFumPXVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dp.message_handler(content_types=types.ContentType.AUDIO)\n",
        "async def handle_audio(message: types.Message):\n",
        "\n",
        "    # Download the audio file\n",
        "    print(\"Downloading the audio file\")\n",
        "    audio_file = await message.audio.download(timeout=60)\n",
        "    print(\"The audio file has been downloaded\")\n",
        "\n",
        "    #Convert audio to text\n",
        "    text = recognize_audio(audio_file.name)\n",
        "\n",
        "    #We send a text in response to the message\n",
        "    await message.reply(text)\n",
        "\n",
        "    #We send a graph that describes emotions in terms of the song's lyrics\n",
        "    await message.reply_photo(open(\"emotions.jpg\",\"rb\"))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    executor.start_polling(dp, skip_updates=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LBhczI4uWrpE",
        "outputId": "0f53cbac-6c02-4580-c37c-3615b1371718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram:Updates were skipped successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the audio file\n",
            "The audio file has been downloaded\n",
            "Processing of 1 segment\n",
            "Processing of 2 segment\n",
            "Processing of 3 segment\n",
            "Processing of 4 segment\n",
            "Processing of 5 segment\n",
            "Processing of 6 segment\n",
            "Processing of 7 segment\n",
            "Processing of 8 segment\n",
            "Processing of 9 segment\n",
            "Processing of 10 segment\n",
            "Processing of 11 segment\n",
            "Processing of 12 segment\n",
            "Processing of 13 segment\n",
            "Processing of 14 segment\n",
            "Processing of 15 segment\n",
            "Processing of 16 segment\n",
            "Processing of 17 segment\n",
            "Processing of 18 segment\n",
            "Processing of 19 segment\n",
            "Processing of 20 segment\n",
            "Processing of 21 segment\n",
            "Processing of 22 segment\n",
            "{'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 'trust': 0.16666666666666666, 'surprise': 0.0, 'positive': 0.6666666666666666, 'negative': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0, 'anticipation': 0.16666666666666666}\n",
            "   Emotion Classification  Emotion Frequency\n",
            "5                positive           0.666667\n",
            "3                   trust           0.166667\n",
            "10           anticipation           0.166667\n",
            "0                    fear           0.000000\n",
            "1                   anger           0.000000\n",
            "2                 anticip           0.000000\n",
            "4                surprise           0.000000\n",
            "6                negative           0.000000\n",
            "7                 sadness           0.000000\n",
            "8                 disgust           0.000000\n",
            "9                     joy           0.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"8248cdcb-95b3-4ed5-bb95-ac1f302707fa\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8248cdcb-95b3-4ed5-bb95-ac1f302707fa\")) {                    Plotly.newPlot(                        \"8248cdcb-95b3-4ed5-bb95-ac1f302707fa\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Emotion Frequency=%{marker.color}<br>Emotion Classification=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.6666666666666666,0.16666666666666666,0.16666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0.6666666666666666,0.16666666666666666,0.16666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"xaxis\":\"x\",\"y\":[\"positive\",\"trust\",\"anticipation\",\"fear\",\"anger\",\"anticip\",\"surprise\",\"negative\",\"sadness\",\"disgust\",\"joy\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Emotion Frequency\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Emotion Classification\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Emotion Frequency\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"height\":400,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8248cdcb-95b3-4ed5-bb95-ac1f302707fa');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram:Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_o6YbrMES-yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJ2uaBWZRIho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}